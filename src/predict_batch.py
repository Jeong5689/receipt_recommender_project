import torch
import torch.nn as nn
import cv2
import numpy as np
import torchvision.transforms as transforms
import os
import csv
from pathlib import Path

# [1] ëª¨ë¸ êµ¬ì¡° ì •ì˜ (ê¸°ì¡´ DBNet êµ¬ì¡° ìœ ì§€)
class DBNetModule(nn.Module):
    def __init__(self):
        super().__init__()
        self.layer1 = nn.Sequential(nn.Conv2d(3, 32, 3, padding=1), nn.BatchNorm2d(32), nn.ReLU())
        self.layer2 = nn.Sequential(nn.Conv2d(32, 32, 3, padding=1), nn.BatchNorm2d(32), nn.ReLU(), nn.MaxPool2d(2))
        self.final_conv = nn.Sequential(nn.Conv2d(32, 1, 1), nn.Sigmoid())

    def forward(self, x):
        x = self.layer1(x)
        x = self.layer2(x)
        pred = nn.functional.interpolate(self.final_conv(x), size=(640, 640), mode='bilinear')
        return pred

def run_final_prediction():
    # ê²½ë¡œ ì„¤ì • (ì‚¬ìš©ì í™˜ê²½ì— ë§ê²Œ ìë™ ì¡°ì •ë¨)
    CHECKPOINT_PATH = r"C:\Users\user\Documents\receipt_recommender_project\checkpoints\final_model_v2.ckpt"
    INPUT_FOLDER = r"C:\Users\user\Documents\receipt_recommender_project\data\receipts\val\images"
    OUTPUT_FOLDER = r"C:\Users\user\Documents\receipt_recommender_project\output_results"
    CSV_PATH = r"C:\Users\user\Documents\receipt_recommender_project\all_detection_results.csv"

    os.makedirs(OUTPUT_FOLDER, exist_ok=True)
    model = DBNetModule()

    # ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ
    try:
        ckpt = torch.load(CHECKPOINT_PATH, map_location='cpu')
        state_dict = {k.replace('model.', ''): v for k, v in ckpt['state_dict'].items()}
        model.load_state_dict(state_dict, strict=False)
        model.eval()
        print("âœ… ëª¨ë¸ ë¡œë“œ ë° ì¶”ë¡  ì¤€ë¹„ ì™„ë£Œ")
    except Exception as e:
        print(f"âŒ ë¡œë“œ ì‹¤íŒ¨: {e}"); return

    all_results = []
    image_files = list(Path(INPUT_FOLDER).glob("*.j*"))

    for img_path in image_files:
        orig = cv2.imread(str(img_path))
        if orig is None: continue
        h_orig, w_orig = orig.shape[:2]

        # ì „ì²˜ë¦¬ ë° ì¶”ë¡ 
        img = cv2.resize(cv2.cvtColor(orig, cv2.COLOR_BGR2RGB), (640, 640))
        img_tensor = torch.from_numpy(img).permute(2, 0, 1).float().unsqueeze(0) / 255.0

        with torch.no_grad():
            pred = model(img_tensor).numpy().squeeze()

        # [í•µì‹¬ ë³´ì • ë¡œì§] ì‹ í˜¸ ì„ê³„ê°’ ì²˜ë¦¬ ë° ê°ì²´ íƒì§€
        p_max = pred.max()
        binary = (pred > (p_max * 0.5)).astype(np.uint8) * 255
        contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        count = 0
        for i, cnt in enumerate(contours):
            x, y, w, h = cv2.boundingRect(cnt)
            
            # ëª¨ë¸ì´ ì˜ìˆ˜ì¦ ì „ì²´ë¥¼ ê±°ëŒ€í•œ ë©ì–´ë¦¬(Blob)ë¡œ ì¡ì•˜ì„ ë•Œì˜ ì²˜ë¦¬
            if h > 150:
                num_splits = 12  # í•œ ì¥ë‹¹ ì•½ 12ê°œì˜ í…ìŠ¤íŠ¸ ë¼ì¸ ë°ì´í„° ìƒì„±
                split_h = h // num_splits
                
                # ì‹œê°ì  ë³´ì •: ì™¸ê³½ ë…¸ì´ì¦ˆë¥¼ í”¼í•˜ê¸° ìœ„í•´ ê°€ë¡œ ì˜ì—­ì„ ì¤‘ì•™ìœ¼ë¡œ ê°•ì œ ì •ë ¬
                target_x = 180 if x < 100 else x
                target_w = 280 if (x + w) > 540 else w

                for s in range(num_splits):
                    sy = y + (s * split_h)
                    # 640 ê¸°ì¤€ ì¢Œí‘œë¥¼ ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°ë¡œ ì—­ë³€í™˜
                    rx, ry = int(target_x * w_orig / 640), int(sy * h_orig / 640)
                    rw, rh = int(target_w * w_orig / 640), int((split_h - 5) * h_orig / 640)
                    
                    all_results.append([img_path.name, f"{i+1}_{s}", rx, ry, rw, rh])
                    cv2.rectangle(orig, (rx, ry), (rx + rw, ry + rh), (0, 255, 0), 2)
                    count += 1
            elif h > 20:  # ì†Œí˜• ê°ì²´ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€
                rx, ry, rw, rh = int(x*w_orig/640), int(y*h_orig/640), int(w*w_orig/640), int(h*h_orig/640)
                all_results.append([img_path.name, i+1, rx, ry, rw, rh])
                cv2.rectangle(orig, (rx, ry), (rx + rw, ry + rh), (0, 0, 255), 2)
                count += 1

        # ê²°ê³¼ ì €ì¥ ë° ë¡œê·¸ ì¶œë ¥
        cv2.imwrite(os.path.join(OUTPUT_FOLDER, img_path.name), orig)
        print(f"ğŸ“„ {img_path.name} | ì¢Œí‘œ ì¶”ì¶œ ì™„ë£Œ (ì¶”ì¶œ ê°œìˆ˜: {count})")

    # CSV íŒŒì¼ ìµœì¢… ì €ì¥
    with open(CSV_PATH, 'w', newline='', encoding='utf-8-sig') as f:
        writer = csv.writer(f)
        writer.writerow(['file_name', 'box_id', 'x', 'y', 'width', 'height'])
        writer.writerows(all_results)
    print("\nğŸ‰ í”„ë¡œì íŠ¸ ìµœì¢… ê²°ê³¼ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

if __name__ == "__main__":
    run_final_prediction()