import torch
import torch.nn as nn
import cv2
import numpy as np
import os
import csv
from pathlib import Path

# [1] ëª¨ë¸ êµ¬ì¡° (ìƒˆ ëª¨ë¸ì˜ ì•„í‚¤í…ì²˜ì— ë§ê²Œ ìˆ˜ì • í•„ìš” ì‹œ ë°˜ì˜)
class DBNetModule(nn.Module):
    def __init__(self):
        super().__init__()
        # ìƒˆë¡œìš´ ëª¨ë¸ì˜ ë ˆì´ì–´ êµ¬ì„± (ê¸°ì¡´ê³¼ ë™ì¼í•˜ë‹¤ë©´ ìœ ì§€)
        self.layer1 = nn.Sequential(nn.Conv2d(3, 32, 3, padding=1), nn.BatchNorm2d(32), nn.ReLU())
        self.layer2 = nn.Sequential(nn.Conv2d(32, 32, 3, padding=1), nn.BatchNorm2d(32), nn.ReLU(), nn.MaxPool2d(2))
        self.final_conv = nn.Sequential(nn.Conv2d(32, 1, 1), nn.Sigmoid())

    def forward(self, x):
        x = self.layer1(x)
        x = self.layer2(x)
        pred = nn.functional.interpolate(self.final_conv(x), size=(640, 640), mode='bilinear')
        return pred

def run_new_model_prediction():
    # ğŸ’¡ ê²½ë¡œ ì„¤ì • (ìƒˆë¡œìš´ ëª¨ë¸ íŒŒì¼ ê²½ë¡œë¡œ ìˆ˜ì •í•˜ì„¸ìš”)
    NEW_CHECKPOINT = r"C:\Users\user\Documents\receipt_recommender_project\checkpoints\final_model_v2.ckpt"
    INPUT_FOLDER = r"C:\Users\user\Documents\receipt_recommender_project\data\receipts\val\images"
    OUTPUT_FOLDER = r"C:\Users\user\Documents\receipt_recommender_project\output_results_new"
    CSV_PATH = r"C:\Users\user\Documents\receipt_recommender_project\final_detection_v2.csv"

# íŒŒì¼ ìƒë‹¨ 30ë²ˆì§¸ ì¤„ ê·¼ì²˜
    NEW_CHECKPOINT = r"C:\Users\user\Documents\receipt_recommender_project\checkpoints\final_model_v2.ckpt"

    os.makedirs(OUTPUT_FOLDER, exist_ok=True)
    model = DBNetModule()

    # ëª¨ë¸ ë¡œë“œ
    # ... (ìƒë‹¨ ì½”ë“œ ë™ì¼)
    model = DBNetModule()

    # ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ (ìƒì„¸ ì—ëŸ¬ ì¶œë ¥ ë²„ì „)
    try:
        if not os.path.exists(NEW_CHECKPOINT):
            print(f"âŒ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {NEW_CHECKPOINT}")
            return

        ckpt = torch.load(NEW_CHECKPOINT, map_location='cpu', weights_only=False)
        
        # 1. State Dict ì¶”ì¶œ (Lightning í˜¹ì€ ì¼ë°˜ PyTorch ì²´í¬í¬ì¸íŠ¸ ëŒ€ì‘)
        if isinstance(ckpt, dict) and 'state_dict' in ckpt:
            state_dict = ckpt['state_dict']
        else:
            state_dict = ckpt
        
        # 2. Key ì´ë¦„ ë§¤ì¹­ (ì ‘ë‘ì–´ 'model.' ì œê±°)
        new_state_dict = {}
        for k, v in state_dict.items():
            name = k.replace('model.', '') # model.layer1 -> layer1
            new_state_dict[name] = v
            
        # 3. ë¡œë“œ ì‹œë„
        msg = model.load_state_dict(new_state_dict, strict=False)
        print(f"âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ! (ì¼ë¶€ ëˆ„ë½ í‚¤ ë¬´ì‹œ: {len(msg.missing_keys)}ê°œ)")
        
        model.eval()
    except Exception as e:
        import traceback
        print("âŒ ìƒì„¸ ë¡œë“œ ì‹¤íŒ¨ ì›ì¸:")
        print(traceback.format_exc()) # ì—ëŸ¬ì˜ êµ¬ì²´ì ì¸ ìœ„ì¹˜ì™€ ì´ìœ ë¥¼ ë‹¤ ë³´ì—¬ì¤ë‹ˆë‹¤.
        return

    all_results = []
    image_files = list(Path(INPUT_FOLDER).glob("*.j*"))

    for img_path in image_files:
        orig = cv2.imread(str(img_path))
        if orig is None: continue
        h_orig, w_orig = orig.shape[:2]

        # ì „ì²˜ë¦¬
        img = cv2.resize(cv2.cvtColor(orig, cv2.COLOR_BGR2RGB), (640, 640))
        img_tensor = torch.from_numpy(img).permute(2, 0, 1).float().unsqueeze(0) / 255.0

        with torch.no_grad():
            pred = model(img_tensor).numpy().squeeze()

        # [ìë™ ì„ê³„ê°’ ì „ëµ] ëª¨ë¸ë§ˆë‹¤ ì‹ í˜¸ ì„¸ê¸°ê°€ ë‹¤ë¥´ë¯€ë¡œ p_max ëŒ€ë¹„ 40% ì§€ì  íƒìƒ‰
        p_max = pred.max()
        thresh = p_max * 0.4
        binary = (pred > thresh).astype(np.uint8) * 255
        
        # ì¤„ ì‚¬ì´ë¥¼ ë–¼ì–´ë†“ê¸° ìœ„í•œ ìˆ˜ì§ ì¹¨ì‹ ì˜ˆì‹œ
        kernel = np.ones((3, 1), np.uint8) # ì„¸ë¡œë¡œ ê¸´ ì»¤ë„
        binary = cv2.erode(binary, kernel, iterations=2)

        contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        count = 0
        for i, cnt in enumerate(contours):
            x, y, w, h = cv2.boundingRect(cnt)
            
            # [ìˆ˜ì •ëœ ë¡œì§] ë°•ìŠ¤ê°€ ë„ˆë¬´ í¬ë©´(ì˜ˆ: ë†’ì´ê°€ 100px ì´ìƒ) ì˜ìˆ˜ì¦ ì „ì²´ë¡œ ê°„ì£¼í•˜ê³  ìª¼ê°­ë‹ˆë‹¤.
            if h > 100: 
                num_lines = 12  # ì˜ìˆ˜ì¦ í•œ ì¥ë‹¹ ëŒ€ëµ 12ì¤„ë¡œ ê°€ì • (ì¡°ì • ê°€ëŠ¥)
                line_h = h // num_lines
                
                for j in range(num_lines):
                    split_y = y + (j * line_h)
                    # ì›ë³¸ ì´ë¯¸ì§€ ì¢Œí‘œë¡œ ë³€í™˜
                    margin = int(w_orig * 0.2) 
                    rx = margin
                    rw = w_orig - (margin * 2)
                    ry = int(split_y * h_orig / 640)
                    rh = int(line_h * h_orig / 640)
                    
                    all_results.append([img_path.name, count + 1, rx, ry, rw, rh])
                    cv2.rectangle(orig, (rx, ry), (rx + rw, ry + rh), (255, 0, 0), 2)
                    count += 1
            
            # ì¼ë°˜ì ì¸ í¬ê¸°ì˜ ë°•ìŠ¤ëŠ” ê·¸ëŒ€ë¡œ ì €ì¥
            elif h > 10 and w > 10:
                rx, ry = int(x * w_orig / 640), int(y * h_orig / 640)
                rw, rh = int(w * w_orig / 640), int(h * h_orig / 640)
                all_results.append([img_path.name, count + 1, rx, ry, rw, rh])
                cv2.rectangle(orig, (rx, ry), (rx + rw, ry + rh), (255, 0, 0), 2)
                count += 1

        cv2.imwrite(os.path.join(OUTPUT_FOLDER, img_path.name), orig)
        print(f"ğŸ“„ {img_path.name} | ìƒˆ ëª¨ë¸ ê²€ì¶œ ì™„ë£Œ: {count}ê°œ")

    # ê²°ê³¼ ì €ì¥
    with open(CSV_PATH, 'w', newline='', encoding='utf-8-sig') as f:
        writer = csv.writer(f)
        writer.writerow(['file_name', 'box_id', 'x', 'y', 'width', 'height'])
        writer.writerows(all_results)
    print(f"ğŸ‰ ì‘ì—… ì™„ë£Œ! CSV í™•ì¸: {CSV_PATH}")

if __name__ == "__main__":
    run_new_model_prediction()